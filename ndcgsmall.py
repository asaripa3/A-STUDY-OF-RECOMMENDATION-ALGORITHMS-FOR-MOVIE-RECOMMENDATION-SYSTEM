# -*- coding: utf-8 -*-
"""ndcgsmall.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lSgkv_3Zh4Z_pi6FCI5Vk8QcTkGqmtRv
"""

from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries
! pip install scikit-surprise
from surprise import SVD
import pandas as pd
from surprise import Dataset
from surprise import Reader
from joblib import Parallel, delayed
import multiprocessing

# Load the Small Latest MovieLens dataset
data = Dataset.load_builtin('ml-100k')

# Convert the dataset into a Pandas DataFrame
df = pd.DataFrame(data.raw_ratings, columns=['user_id', 'item_id', 'rating', 'timestamp'])

# View the first few rows of the DataFrame and shape
print(df.head(10))
print(df.shape[0])

from surprise.model_selection import train_test_split
# Split the data into training and testing sets
trainset, testset = train_test_split(data, test_size=0.25, random_state=32)

# Convert the trainset to a pandas dataframe
trainset_df = pd.DataFrame(trainset.build_testset(), columns=['user_id', 'item_id', 'rating'])

# Convert the testset to a pandas dataframe
testset_df = pd.DataFrame(testset, columns=['user_id', 'item_id', 'rating'])

print(trainset_df.head(10))
print(trainset_df.shape[0])

# View the first few rows of testset
print(testset_df.head(10))
print(testset_df.shape[0])

# Define the SVD algorithm with optimized parameters
algo = SVD(n_factors=100, n_epochs=20, biased=True, lr_all=0.005, reg_all=0.2)

# Fit the algorithm on the training set
algo.fit(trainset)

# Use the trained SVD algorithm to generate recommendations for each user in the test set
test_predictions = algo.test(testset)

"""Calculating metrics"""

from surprise import accuracy
from sklearn.metrics import precision_score, recall_score, f1_score
import numpy as np

threshold = 3.5  # The threshold for considering a movie as liked

predictions_binary = np.array([1 if p.est >= threshold else 0 for p in test_predictions])
testset_binary = np.array([1 if r >= threshold else 0 for (_, _, r) in testset])

# Calculate precision
precision = precision_score(testset_binary, predictions_binary)
print(f'Precision: {precision:.3f}')

# Calculate recall
recall = recall_score(testset_binary, predictions_binary)
print(f'Recall: {recall:.3f}')

# Calculate f1 score
f1 = f1_score(testset_binary, predictions_binary)
print(f'F1 score: {f1:.3f}')

# Calculate MAE, MSE, and RMSE
mae = accuracy.mae(test_predictions)
mse = accuracy.mse(test_predictions)
rmse = accuracy.rmse(test_predictions)

# Print the results
print(f'MAE: {mae:.3f}')
print(f'MSE: {mse:.3f}')
print(f'RMSE: {rmse:.3f}')

"""Make Predictions"""

# Get the list of all movie ids in the dataset
movie_ids = [rating[1] for rating in data.raw_ratings]
movie_ids = list(set(movie_ids))

# Let's say we want to recommend movies for user with id 1
user_id = 1492

# Get the list of movie ids that the user has already seen
seen_movies = [m for (u, m, _) in testset if u == user_id]
# Get the list of movie ids that the user has not seen
unseen_movies = list(set(movie_ids) - set(seen_movies))

# Print the number of unseen_movies
print(len(unseen_movies))

# Predict the ratings for the unseen movies
predictions = [algo.predict(user_id, movie_id) for movie_id in unseen_movies]

# Sort the predictions by estimated rating in descending order
predictions.sort(key=lambda x: x.est, reverse=True)

# Join the movie names with the movie ids
movies = pd.read_csv('/content/drive/MyDrive/4-2project/movies.csv')
movie_dict = dict(zip(movies['movieId'], movies['title']))

# Predict the ratings for the unseen movies
predictions = [algo.predict(user_id, movie_id) for movie_id in unseen_movies]

# Sort the predictions by estimated rating in descending order
predictions.sort(key=lambda x: x.est, reverse=True)

# Print the top 10 recommendations
for i in range(10):
    movie_id = predictions[i].iid
    movie_name = movie_dict[movie_id]
    print(f"{i+1}. {movie_name}")